{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image recognization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# call the model and test\n",
    "from skimage import io,transform\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the directory of data\n",
    "path = './flower_photos/'\n",
    "# the saved modle directory\n",
    "model_path = './model/'\n",
    "# the name of modle\n",
    "model_name = 'CNN_model-4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test images\n",
    "path1 = \"daisy/5547758_eea9edfd54_n.jpg\"\n",
    "path2 = \"roses/394990940_7af082cf8d_n.jpg\"\n",
    "path3 = \"dandelion/7355522_b66e5d3078_m.jpg\"\n",
    "path4 = \"tulips/10791227_7168491604.jpg\"\n",
    "path5 = \"sunflowers/6953297_8576bf4ea3.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = path+path1\n",
    "path2 = path+path2\n",
    "path3 = path+path3\n",
    "path4 = path+path4\n",
    "path5 = path+path5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_dict = {0:'dasiy',1:'dandelion',2:'roses',3:'sunflowers',4:'tulips'}\n",
    "w=100\n",
    "h=100\n",
    "c=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read test image and resize the images\n",
    "def read_one_image(path):\n",
    "    img = io.imread(path)\n",
    "    img = transform.resize(img,(w,h),mode='constant')\n",
    "    return np.asarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "# prepare the data\n",
    "data = []\n",
    "data1 = read_one_image(path1)\n",
    "data2 = read_one_image(path2)\n",
    "data3 = read_one_image(path3)\n",
    "data4 = read_one_image(path4)\n",
    "data5 = read_one_image(path5)\n",
    "data.append(data1)\n",
    "data.append(data2)\n",
    "data.append(data3)\n",
    "data.append(data4)\n",
    "data.append(data5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./model/CNN_model-4\n",
      "[[0.0055 0.0024 0.0004 0.9838 0.0078]\n",
      " [0.     0.001  0.     0.     0.9989]\n",
      " [0.7593 0.0122 0.0258 0.2004 0.0024]\n",
      " [0.0003 0.5508 0.0075 0.0071 0.4343]\n",
      " [0.0002 0.0259 0.9736 0.0002 0.0002]]\n",
      "[3 4 0 1 2]\n",
      "The prediction of fisrt flower is:sunflowers\n",
      "The prediction of second flower is:tulips\n",
      "The prediction of third flower is:dasiy\n",
      "The prediction of fourth flower is:dandelion\n",
      "The prediction of fifth flower is:roses\n"
     ]
    }
   ],
   "source": [
    "# start the session\n",
    "with tf.Session() as sess:\n",
    "    #latrest model path\n",
    "    model_file=tf.train.latest_checkpoint(model_path)\n",
    "    # import computive graph\n",
    "    saver = tf.train.import_meta_graph(model_file+'.meta')\n",
    "    # restore weight ingformation\n",
    "    saver.restore(sess, model_file) \n",
    "    graph = tf.get_default_graph()\n",
    "    # calculate the input nodes in graph\n",
    "    x = graph.get_tensor_by_name(\"x:0\")\n",
    "    # feed information\n",
    "    feed_dict = {x:data}\n",
    "    # calculate the output nodes in graph\n",
    "    logits = graph.get_tensor_by_name(\"logits_eval:0\")\n",
    "    # run the session\n",
    "    classification_result = sess.run(logits,feed_dict)\n",
    "    #diplay 4 decimals\n",
    "    np.set_printoptions(precision=4, suppress=True)\n",
    "    #print the prediction \n",
    "    print(classification_result)\n",
    "    #print the maximum in the matrix\n",
    "    print(tf.argmax(classification_result,1).eval())\n",
    "    #Match category of flowers\n",
    "    output = []\n",
    "    output = tf.argmax(classification_result,1).eval()\n",
    "    name=[\"fisrt\",\"second\",\"third\",\"fourth\",\"fifth\"]\n",
    "    for i in range(len(output)):\n",
    "        print(\"The prediction of %s flower is:\" %(name[i])+flower_dict[output[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
